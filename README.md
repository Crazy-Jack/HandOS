# HandOS
Hacking a hand operating system that use hand gesture for interface. 


This this project, I am trying to creating a computer interface that eliminates the needs of using touchpad. Using hand gesture to move the windows, therefore eliminating the needs of touch pad. The eventual goal is to integrate this hand gesture system with the next generation AR operating system so that people can have a finer and more immersive control when using the AR glass. 

Let's first break down the system into several parts. 

1. Hand gesture recognition
   We need a system that can recognize the hand gesture entirely from the camera. There are planty of built neural network to do that reliablely. See the following resources:

    - https://www.youtube.com/watch?v=a99p_fAr6e4

2. Mapping the hand gesture to the touchpad gesture.

   The first step to make a prototype is just making the hand gesture to replace the touch pad.

   If this is successful, then you can generalize it to more operating system control.

3. Generalize it to 3D vision.

   The actual advance of immersive interactive experience lies in generalizing it from 2D to 3D. If you can make the 2D screen into 3D and wear a 3D eye glasses to see. 
   
